{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with Foundation Models\n",
        "copyright 2023 Denis Rothman, MIT License\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "This notebook explores GPT-3, GPT-3.5 turbo(ChatGPT) and GPT-4 models. Each model is implemented for each task. Which one should you choose for your project? \n",
        "\n",
        "Let's ask GPT-4 to guide us through this challenging question.\n",
        "\n",
        "**Denis Rothman:**What do you really need for NLP tasks: GPT-3, GPT-3.5-turbo, or GPT-4? \n",
        "\n",
        "**GPT-4** The choice between GPT-3, GPT-3.5-turbo, and GPT-4 for NLP tasks depends on your specific requirements, such as the level of complexity, budget, and the desired balance between response time and accuracy. Here's a general guideline for choosing between these models:\n",
        "\n",
        "GPT-3: This model provides a good balance of capability, cost, and response time. If your NLP tasks are moderately complex and you are looking for an affordable option that delivers reliable performance, GPT-3 engines like Curie or Babbage can be suitable.\n",
        "\n",
        "GPT-3.5-turbo: Designed to offer similar capabilities as GPT-3's Davinci engine but at a lower cost per token, GPT-3.5-turbo can be a suitable choice if you want a powerful engine with a more cost-effective approach. Use it for tasks that require more creativity and nuanced understanding without breaking the bank.\n",
        "\n",
        "GPT-4: As the most advanced model in this series, GPT-4 can be the best choice for highly complex NLP tasks that demand superior performance, understanding, and creativity. If you are working on cutting-edge applications or need a top-tier language model for research, GPT-4 may be the right choice. However, keep in mind that GPT-4 could be more expensive and have slower response times compared to the other options.\n",
        "\n",
        "Ultimately, the choice depends on your project's specific requirements, budget, and the desired trade-offs between performance and cost. It can be helpful to experiment with different models and engines to find the one that best fits your needs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you really need for NLP tasks: GPT-3, GPT-3.5-turbo, or GPT-4? Run each task in the notebook to decide.\n"
      ],
      "metadata": {
        "id": "N_1BX64UZE3g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "##  Installing & importing Openai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "##  Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl1yS4tJeYI2",
        "outputId": "661960e2-f190-4646-c45c-7a41c8796ac6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6uKDkb3y7QZ"
      },
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Engines"
      ],
      "metadata": {
        "id": "JFIIICtDEwRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### List of Engines\n",
        "\n",
        "[OpenAI models](https://platform.openai.com/docs/models/overview) include engines. \n",
        "\n",
        "What is the difference between OpenAI models and engines?\n",
        "\n",
        "**Denis Rothman:** OpenAI has several models such as GPT-3, GPT-3.5-turbo, and GPT-4. OpenAI also has several engines. What is the difference between the models and the engines?\n",
        "\n",
        "**GPT-4:** OpenAI's models refer to different versions or iterations of their language models, each with distinct capabilities, complexity, and performance. GPT-3, GPT-3.5-turbo, and GPT-4 are examples of different models, with GPT-4 being the most advanced version in the series you mentioned.\n",
        "\n",
        "On the other hand, engines are specific configurations or instances of a given model, tailored to provide different levels of performance, cost, and use cases. Each engine has a different balance of capabilities, such as response time, token limits, and creative output.\n",
        "\n",
        "To clarify, let's consider GPT-3 as an example. GPT-3 has several engines associated with it, including:\n",
        "\n",
        "Davinci: The most capable and creative engine, suitable for complex tasks but with a higher cost per token and slower response time.\n",
        "Curie: A more balanced engine, offering a mix of capability and cost efficiency.\n",
        "Babbage: A faster and more cost-effective engine, ideal for less complex tasks that require less creative responses.\n",
        "Ada: The fastest and most affordable engine, suitable for straightforward tasks that don't demand high creativity.\n",
        "In summary, models represent different versions of OpenAI's language models, while engines are various configurations of those models, each designed to address specific needs and use cases.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qzHMeedba1SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elist=openai.Engine.list()"
      ],
      "metadata": {
        "id": "smyf1O9yEyac"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length=len(elist[\"data\"])\n",
        "print(\"Number of Engines: \",length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn4ALmhTFO97",
        "outputId": "700926e1-5229-4af2-bb1d-fa3d178c9cfb"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Engines:  56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ef=open('engines.txt','w')\n",
        "ef.write(\"engine\")\n",
        "ef.write('\\n')\n",
        "l=0\n",
        "for i in range(0,length):\n",
        "  try:\n",
        "    el=elist[\"data\"][i][\"id\"]\n",
        "    print(i,el)\n",
        "    ef.write(str(el))\n",
        "    ef.write('\\n')\n",
        "  except:\n",
        "    print(\"number of engines: \",i)\n",
        "\n",
        "ef.close()"
      ],
      "metadata": {
        "id": "TdOYy7kxF3XE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec5d490-804d-4469-f684-9fe25eb33736"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 babbage\n",
            "1 davinci\n",
            "2 babbage-code-search-code\n",
            "3 text-similarity-babbage-001\n",
            "4 text-davinci-001\n",
            "5 ada\n",
            "6 curie-instruct-beta\n",
            "7 babbage-code-search-text\n",
            "8 babbage-similarity\n",
            "9 gpt-3.5-turbo\n",
            "10 code-search-babbage-text-001\n",
            "11 gpt-4-0314\n",
            "12 gpt-3.5-turbo-0301\n",
            "13 code-cushman-001\n",
            "14 code-search-babbage-code-001\n",
            "15 gpt-4\n",
            "16 text-ada-001\n",
            "17 text-embedding-ada-002\n",
            "18 text-similarity-ada-001\n",
            "19 text-davinci-insert-002\n",
            "20 ada-code-search-code\n",
            "21 ada-similarity\n",
            "22 whisper-1\n",
            "23 text-davinci-003\n",
            "24 code-search-ada-text-001\n",
            "25 text-search-ada-query-001\n",
            "26 text-curie-001\n",
            "27 text-davinci-edit-001\n",
            "28 davinci-search-document\n",
            "29 ada-code-search-text\n",
            "30 text-search-ada-doc-001\n",
            "31 code-davinci-edit-001\n",
            "32 davinci-instruct-beta\n",
            "33 code-davinci-002\n",
            "34 text-similarity-curie-001\n",
            "35 code-search-ada-code-001\n",
            "36 ada-search-query\n",
            "37 text-search-davinci-query-001\n",
            "38 curie-search-query\n",
            "39 davinci-search-query\n",
            "40 text-davinci-insert-001\n",
            "41 babbage-search-document\n",
            "42 ada-search-document\n",
            "43 text-search-curie-query-001\n",
            "44 text-search-babbage-doc-001\n",
            "45 text-davinci-002\n",
            "46 curie-search-document\n",
            "47 text-search-curie-doc-001\n",
            "48 babbage-search-query\n",
            "49 text-babbage-001\n",
            "50 text-search-davinci-doc-001\n",
            "51 text-search-babbage-query-001\n",
            "52 curie-similarity\n",
            "53 curie\n",
            "54 text-similarity-davinci-001\n",
            "55 davinci-similarity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('engines.txt')\n",
        "df.sort_values(['engine'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7axwv7spi6j7",
        "outputId": "44909b2c-4489-4de7-82c8-88793a886687"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           engine\n",
              "5                             ada\n",
              "20           ada-code-search-code\n",
              "29           ada-code-search-text\n",
              "42            ada-search-document\n",
              "36               ada-search-query\n",
              "21                 ada-similarity\n",
              "0                         babbage\n",
              "2        babbage-code-search-code\n",
              "7        babbage-code-search-text\n",
              "41        babbage-search-document\n",
              "48           babbage-search-query\n",
              "8              babbage-similarity\n",
              "13               code-cushman-001\n",
              "33               code-davinci-002\n",
              "31          code-davinci-edit-001\n",
              "35       code-search-ada-code-001\n",
              "24       code-search-ada-text-001\n",
              "14   code-search-babbage-code-001\n",
              "10   code-search-babbage-text-001\n",
              "53                          curie\n",
              "6             curie-instruct-beta\n",
              "46          curie-search-document\n",
              "38             curie-search-query\n",
              "52               curie-similarity\n",
              "1                         davinci\n",
              "32          davinci-instruct-beta\n",
              "28        davinci-search-document\n",
              "39           davinci-search-query\n",
              "55             davinci-similarity\n",
              "9                   gpt-3.5-turbo\n",
              "12             gpt-3.5-turbo-0301\n",
              "15                          gpt-4\n",
              "11                     gpt-4-0314\n",
              "16                   text-ada-001\n",
              "49               text-babbage-001\n",
              "26                 text-curie-001\n",
              "4                text-davinci-001\n",
              "45               text-davinci-002\n",
              "23               text-davinci-003\n",
              "27          text-davinci-edit-001\n",
              "40        text-davinci-insert-001\n",
              "19        text-davinci-insert-002\n",
              "17         text-embedding-ada-002\n",
              "30        text-search-ada-doc-001\n",
              "25      text-search-ada-query-001\n",
              "44    text-search-babbage-doc-001\n",
              "51  text-search-babbage-query-001\n",
              "47      text-search-curie-doc-001\n",
              "43    text-search-curie-query-001\n",
              "50    text-search-davinci-doc-001\n",
              "37  text-search-davinci-query-001\n",
              "18        text-similarity-ada-001\n",
              "3     text-similarity-babbage-001\n",
              "34      text-similarity-curie-001\n",
              "54    text-similarity-davinci-001\n",
              "22                      whisper-1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-149b6a25-bed1-4a7c-813b-a64945831f5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>engine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ada-code-search-code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>ada-code-search-text</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>ada-search-document</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>ada-search-query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ada-similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>babbage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>babbage-code-search-code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>babbage-code-search-text</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>babbage-search-document</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>babbage-search-query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>babbage-similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>code-cushman-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>code-davinci-002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>code-davinci-edit-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>code-search-ada-code-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>code-search-ada-text-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>code-search-babbage-code-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>code-search-babbage-text-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>curie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>curie-instruct-beta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>curie-search-document</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>curie-search-query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>curie-similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>davinci</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>davinci-instruct-beta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>davinci-search-document</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>davinci-search-query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>davinci-similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>gpt-3.5-turbo-0301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>gpt-4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>gpt-4-0314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>text-ada-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>text-babbage-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>text-curie-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>text-davinci-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>text-davinci-002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>text-davinci-003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>text-davinci-edit-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>text-davinci-insert-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>text-davinci-insert-002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>text-embedding-ada-002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>text-search-ada-doc-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>text-search-ada-query-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>text-search-babbage-doc-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>text-search-babbage-query-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>text-search-curie-doc-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>text-search-curie-query-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>text-search-davinci-doc-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>text-search-davinci-query-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>text-similarity-ada-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>text-similarity-babbage-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>text-similarity-curie-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>text-similarity-davinci-001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>whisper-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-149b6a25-bed1-4a7c-813b-a64945831f5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-149b6a25-bed1-4a7c-813b-a64945831f5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-149b6a25-bed1-4a7c-813b-a64945831f5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks\n",
        "\n",
        "Run each cell and analyze the outputs in detail. You will see that you don't always need the most powerful model to solve a problem. Sometimes you do. \n",
        "\n",
        "Take your time. Conduct your own experiments with your inputs.\n"
      ],
      "metadata": {
        "id": "nQKSYQbxP7LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dialog function for GPT-3.5-turbo and GPT-4\n",
        "\n",
        "Note: GPT-3.5 and GPT-4 are conversational AI models that do not have the same format as GPT-3 models.\n",
        "\n",
        "For more on the parameters applied to the engines, read *Transformers for NLP, 2nd Edition, Chapter 7, The Rise of Suprahuman with GPT-3 Engines*. GPT-3.5-turbo and GPT-4 are GPT models that it is important to understand to make the right choices. "
      ],
      "metadata": {
        "id": "muBxqke2MpOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing a message for chat models\n",
        "def prepare_message(uinput):\n",
        " #preparing the prompt for OpenAI \n",
        " role=\"user\"\n",
        " #prompt=\"Where is Tahiti located?\" #maintenance or if you do not want to use a microphone\n",
        " line = {\"role\": role, \"content\": uinput}\n",
        " \n",
        " #creating the mesage\n",
        " assert1={\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
        " assert2={\"role\": \"assistant\", \"content\": \"Geography is an important topic if you are going on a once in a lifetime trip.\"}\n",
        " assert3=line\n",
        " iprompt = []\n",
        " iprompt.append(assert1)\n",
        " iprompt.append(assert2)\n",
        " iprompt.append(assert3)\n",
        "\n",
        "\n",
        " return iprompt"
      ],
      "metadata": {
        "id": "6KqfSmZfN6DW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solving Word Math Problems"
      ],
      "metadata": {
        "id": "xVEwDI5DhZfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT-3 davinci engine\n",
        "p1=\"davinci\"\n",
        "p2=\"The total capacity of two warehouses is 12000 units + 4000 units, the first warehouse can store 1000 additional units but the second warehouse has problems so it can only store 2000 units =\",\n",
        "p3=0.0\n",
        "p4=5\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbIMEg1DHK4E",
        "outputId": "cc92e752-8bb5-4416-975d-f29a0a948ae1"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 12000 + 1000 +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"The total capacity of two warehouses is 12000 units + 4000 units, the first warehouse can store 1000 additional units but the second warehouse has problems so it can only store 2000 units =\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz8FnQMuPc1S",
        "outputId": "04809d96-e01d-4a6b-cb16-e71e1f23445e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The total storage capacity of the first warehouse is 12000 + 1000 = 13000 units.\n",
            "The remaining storage capacity of the second warehouse after deducting 2000 units is 4000 - 2000 = 2000 units.\n",
            "Therefore, the total storage capacity of both warehouses is 13000 + 2000 = 15000 units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"The total capacity of two warehouses is 12000 units + 4000 units, the first warehouse can store 1000 additional units but the second warehouse has problems so it can only store 2000 units =\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPjQDWIGNPiR",
        "outputId": "2a545221-8f5f-4ce1-d4a8-bbf43182796e"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The total capacity of the two warehouses is 12,000 units + 4,000 units = 16,000 units. Now, taking into account the changes in capacity:\n",
            "\n",
            "1. The first warehouse can store an additional 1,000 units, so its new capacity is 12,000 + 1,000 = 13,000 units.\n",
            "2. The second warehouse has problems and can only store 2,000 units, so its capacity is reduced from 4,000 to 2,000 units.\n",
            "\n",
            "The revised total capacity of the two warehouses is 13,000 units (first warehouse) + 2,000 units (second warehouse) = 15,000 units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Instruct series\n",
        "\n",
        "https://beta.openai.com/docs/engines/instruct-series-beta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2oL0NLRNI3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4c9eef-1536-4664-d95a-a6abca46c377"
      },
      "source": [
        "p1=\"davinci-instruct-beta\"\n",
        "p2=\"Write a plan of actions based on these instructions:\\n\\nStart Chrome.\\nYou have to eventually click on the advanced tab.\\nHowever before, click on the Internet options on the tools menu.\\nThen click on the advanced tab, then click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\"\n",
        "p3=0\n",
        "p4=120\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Open Chrome\n",
            "2. Click on the \"Tools\" menu\n",
            "3. Click on \"Internet Options\"\n",
            "4. Click on the \"Advanced\" tab\n",
            "5. Click on the \"Personalized Favorite Menu\" checkbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Write a plan of actions based on these instructions:\\n\\nStart Chrome.\\nYou have to eventually click on the advanced tab.\\nHowever before, click on the Internet options on the tools menu.\\nThen click on the advanced tab, then click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vmsD05iP8m5",
        "outputId": "bb808d81-11bd-4784-894f-2c28e5116707"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: 1. Click on the Chrome icon to open the browser.\n",
            "2. Look for and click on the \"Tools\" menu located at the top right corner of the browser window.\n",
            "3. Select the \"Internet options\" from the drop-down menu.\n",
            "4. In the \"Internet Options\" window, click on the \"Advanced\" tab at the top.\n",
            "5. Scroll down until you find the \"Enable personalized favorite menu\" option. If the box is already unchecked, skip to step 7.\n",
            "6. Click on the checkbox to enable the option.\n",
            "7. Click on the checkbox again to uncheck it.\n",
            "8. Click on \"Apply\" and then \"OK\" to save the changes.\n",
            "9. Close the Internet Options window.\n",
            "10. You can now continue browsing normally.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Write a plan of actions based on these instructions:\\n\\nStart Chrome.\\nYou have to eventually click on the advanced tab.\\nHowever before, click on the Internet options on the tools menu.\\nThen click on the advanced tab, then click to clear or select the enable\\npersonalized favorite menu check box.\\n\\n\\nACTIONS:\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWt3vSr3QVzc",
        "outputId": "8648341d-ac9b-4c81-a709-5097b2a445aa"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: 1. Open Google Chrome browser.\n",
            "2. Locate the Tools menu (three vertical dots in the top-right corner).\n",
            "3. Click on the Tools menu and select \"Internet Options\" from the dropdown.\n",
            "4. In the Internet Options window, navigate to the \"Advanced\" tab.\n",
            "5. Find the \"Enable Personalized Favorite Menu\" check box.\n",
            "6. Click on the checkbox to either clear (disable) or select (enable) the feature as needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recipe Generator"
      ],
      "metadata": {
        "id": "jN5SnYbncR4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1=\"davinci-instruct-beta\"\n",
        "p2=\"Write a recipe based on these ingredients and instructions:\\n\\nFrito Pie\\n\\nIngredients:\\nFritos\\nChili\\nShredded cheddar cheese\\nSweet white or red onions, diced small\\nSour cream\\n\\nDirections:\"\n",
        "p3=0\n",
        "p4=120\n",
        "p5=1.0\n",
        "p6=0.0\n",
        "p7=0.0\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N0VqdJzcUYK",
        "outputId": "3ea4207c-87c5-4089-916b-bc55064695cd"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Heat the chili in a pot on the stove.\n",
            "2. Place a layer of Fritos in the bottom of a bowl.\n",
            "3. Top with chili, shredded cheese, diced onions, and sour cream.\n",
            "4. Repeat until the bowl is full.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Write a recipe based on these ingredients for a Frito Pie with these ingredients:Fritos,Chili,Shredded cheddar cheese,Sweet white or red onions, diced small,sour cream\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe2ijVLDWeu5",
        "outputId": "14aeba90-d7e2-4aca-de04-3481aed16f39"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: Here's a recipe for Frito Pie using the ingredients you listed:\n",
            "\n",
            "Ingredients:\n",
            "- 4 cups of Fritos\n",
            "- 2 cans of chili (15 oz each)\n",
            "- 2 cups of shredded cheddar cheese\n",
            "- 1/2 cup of diced sweet white or red onions\n",
            "- 1/2 cup of sour cream\n",
            "\n",
            "Instructions:\n",
            "\n",
            "1. Preheat your oven to 350F.\n",
            "\n",
            "2. Spread a layer of Fritos at the bottom of a 9x13 inch baking dish.\n",
            "\n",
            "3. Pour one can of chili over the Fritos.\n",
            "\n",
            "4. Sprinkle half of the shredded cheddar cheese over the chili.\n",
            "\n",
            "5. Add another layer of Fritos on top of the cheese.\n",
            "\n",
            "6. Pour the second can of chili over the Fritos.\n",
            "\n",
            "7. Sprinkle the remaining shredded cheddar cheese on top.\n",
            "\n",
            "8. Bake for 20-25 minutes, or until the cheese is melted and bubbly.\n",
            "\n",
            "9. Remove the dish from the oven and sprinkle the diced onions on top.\n",
            "\n",
            "10. Serve with a dollop of sour cream on each piece of Frito Pie.\n",
            "\n",
            "Enjoy your delicious Frito Pie!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Write a recipe based on these ingredients for a Frito Pie with these ingredients:Fritos,Chili,Shredded cheddar cheese,Sweet white or red onions, diced small,sour cream\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTCpjKxLXP8V",
        "outputId": "5278a61b-806b-4fb4-fe45-da2ca3cfa38a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: Frito Pie Recipe\n",
            "\n",
            "Ingredients:\n",
            "- 1 (9.25 oz) bag of Fritos Original Corn Chips\n",
            "- 2 cups of homemade or store-bought chili, heated (about 15 oz)\n",
            "- 2 cups shredded cheddar cheese\n",
            "- 1 sweet white or red onion, diced small\n",
            "- 1/2 cup sour cream\n",
            "\n",
            "Instructions:\n",
            "\n",
            "1. Preheat the oven to 375F (190C).\n",
            "\n",
            "2. In a 9x13 inch baking dish, create a layer using half of the Fritos corn chips. Spread them evenly across the bottom of the dish.\n",
            "\n",
            "3. Pour half of the heated chili (1 cup) on top of the Fritos layer, and use a spoon or spatula to spread it evenly.\n",
            "\n",
            "4. Sprinkle half of the diced sweet onions (about 1/4 cup) over the chili layer.\n",
            "\n",
            "5. Next, sprinkle 1 cup of shredded cheddar cheese evenly over the onions.\n",
            "\n",
            "6. Repeat the process with the remaining Fritos, chili, onions, and cheese  creating a second layer of each ingredient.\n",
            "\n",
            "7. Place the baking dish into the preheated oven and bake for 15 to 20 minutes, or until the cheese is melted, bubbly, and lightly browned.\n",
            "\n",
            "8. Remove the Frito Pie from the oven, and allow it to cool for about 5 minutes, as it will be very hot.\n",
            "\n",
            "9. Top each serving with a dollop of sour cream, and serve with a spoon or spatula. Enjoy your delicious Frito Pie!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1=\"davinci\"\n",
        "question=\"What is the best cake?\"\n",
        "p2=\"Q:\"+ question + \"\\nA:\"\n",
        "p3=0.7\n",
        "p4=10\n",
        "p5=0.7\n",
        "p6=0\n",
        "p7=0\n",
        "p8=[\"\\n\"]\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,stop=p8,logprobs=5)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCm74nU9LF9Q",
        "outputId": "3271413e-b5e0-42df-9f6e-53d7da31d1b7"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The one you like the most.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"What is the best cake?\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eELnB9TnXkWd",
        "outputId": "e98ca1bf-d249-4e6b-8766-037d15dbd4b6"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: As an AI language model, I don't have personal preferences or tastes, but some of the most popular cakes around the world are chocolate cake, red velvet cake, vanilla cake, carrot cake, cheesecake, fruitcake, and many more. The best cake would depend on individual preferences and tastes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"What is the best cake?\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ois9G2XrJR",
        "outputId": "c2bbd311-aef2-475e-e7cb-123f2a7e40b6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The \"best\" cake is subjective and depends on individual preferences. Some popular cake options include chocolate cake, red velvet cake, carrot cake, and cheesecake. The best cake for you would be the one you enjoy the most, whether it's due to its taste, texture, or appearance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Movie to emoji\n",
        "\n",
        "https://beta.openai.com/examples/default-movie-to-emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUOH-fAbawlc",
        "outputId": "0e59aef2-60fe-4766-a1c7-b26563b85a87"
      },
      "source": [
        "p1=\"davinci\"\n",
        "p2=\"Back to Future: \\nBatman: \\nTransformers: \\nWonder Woman: \\nWinnie the Pooh: \\nThe Godfather: \\nGame of Thrones: \\nSpider-Man:\"\n",
        "p3=0.8\n",
        "p4=60\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "p8=[\"\\n\"]\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,stop=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Show me the movie Spiderman in emojis: \"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu5jdfQNTgDs",
        "outputId": "6f018b14-7e3a-4f99-82de-e49cd1439812"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Show me the movie Spiderman in emojis: \"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syTmj5cGTtJc",
        "outputId": "cdb9c51c-0db4-4043-d2ee-49094040b7de"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1=\"davinci\"\n",
        "p2=\"Show me this sentence in emojis:\"\n",
        "p3=0.8\n",
        "p4=60\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "p8=[\"\\n\"]\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,stop=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97s7U1dsexe0",
        "outputId": "109bf928-2bcc-44d4-efd2-651138abd76b"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A general knowledge question\n",
        "\n",
        "March 2023 comment: note that GPT-4 doesn't know it is GPT-4 because the dataset cutoff was maybe made before OpenAI named the model \"gpt-4.\""
      ],
      "metadata": {
        "id": "daHTJIoZVI6k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89d4621-cab2-4850-8375-89ada54f0efc",
        "id": "Bt4Hfqv_bZwx"
      },
      "source": [
        "p1=\"davinci\"\n",
        "p2=\"Q: What is GPT-4?\\nA:\"\n",
        "p3=0\n",
        "p4=50\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "p8=[\"\\n\"]\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,stop=p8,logprobs=5)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GPT-4 is a new type of GPT that is designed to be more secure than the original GPT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"What is GPT-4?\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETrDtG45Yms5",
        "outputId": "0d7a483c-5067-4f61-f7f9-5d882957b1ca"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: \n",
            "\n",
            "As an AI language model, I do not have any information about GPT-4 because it is a hypothetical model that does not exist. The current cutting-edge model in the GPT (Generative Pretrained Transformer) series is GPT-3, which uses machine learning to generate human-like responses to various tasks, such as text completion, translation, and conversation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"What is GPT-4?\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GvzVmjZYtvf",
        "outputId": "063e8beb-c9f2-4b06-9dfc-fa692fe84ae2"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: As of now, GPT-4 does not exist. GPT stands for \"Generative Pre-trained Transformer,\" and it is an advanced language processing AI model developed by OpenAI. The most recent version at the moment is GPT-3, which has been garnering attention for its capabilities in understanding and generating human-like sentences. GPT-4, if it were to be released, would be the next iteration in the GPT series, presumably possessing even more advanced language understanding and generation capabilities than its predecessor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsafe content can go undetected "
      ],
      "metadata": {
        "id": "NPIwffV5eSVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content_to_classify = \"Never get vaccinated. Who f;;k;;g cares.\"\n",
        "p1=\"content-filter-alpha\"\n",
        "p2 = \"<|endoftext|>\"+content_to_classify+\"\\n--\\nLabel:\"\n",
        "p3=0\n",
        "p4=1\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "p8=10\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,logprobs=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417cea97-762a-413e-d45c-1adb35b6160e",
        "id": "j-sq9fGudKfE"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Is this content safe:Never get vaccinated. Who f;;k;;g cares.\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVvq4zNFVZul",
        "outputId": "c39cc60c-e5dc-4d79-fb51-93b0565c3d55"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: No, the content is not safe. It is not recommended to spread misinformation and encourage people to neglect their health by not getting vaccinated. Vaccines are an essential tool that helps protect us against serious illnesses, and it is important to prioritize our health and the health of those around us by following the advice of medical professionals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Is this content safe:Never get vaccinated. Who f;;k;;g cares.\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sFTMheCViTq",
        "outputId": "29db06fc-a73a-478b-e8ae-62ac7c3c1d66"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: As an AI language model, I cannot provide real-time opinions on content safety. However, I can tell you that the statement you shared appears to be against vaccinations. Vaccinations have been proven to be effective in preventing various diseases and maintaining public health. It's essential to consult with healthcare professionals and rely on science-based information when making decisions related to vaccinations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content_to_classify = \"The say doses are good. But I agree with Djoko.\"\n",
        "p1=\"content-filter-alpha\"\n",
        "p2 = \"<|endoftext|>\"+content_to_classify+\"\\n--\\nLabel:\"\n",
        "p3=0\n",
        "p4=1\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "p8=10\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,logprobs=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])\n",
        "\n",
        "saving(\"E7624.json\", response)\n",
        "#loading(\"E7624.json\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_XTLwjae7pU",
        "outputId": "14e62f5c-8c88-4dba-c0af-d71d9db9057b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Is the following content safe: The say doses are good. But I agree with Djoko.\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWpm67fpSxs0",
        "outputId": "7159a54a-c238-4c7b-b739-5215f9775753"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: As an AI language model, I cannot determine the context of the content, but based on the text alone, it does not appear to have any inappropriate or harmful elements. However, without knowing the context, it is difficult to provide a definitive answer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Is the following content safe: The say doses are good. But I agree with Djoko.\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ZhaWC_S9kK",
        "outputId": "54281fbe-3748-4675-da7f-d20aa0b65832"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: It appears that the content is discussing opinions about doses and mentioning an agreement with someone named Djoko. However, without more context, it's difficult to determine if this content is related to something safe or unsafe. Please provide more information or context to better understand the topic being discussed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example of a negative Tweet that can go undetected."
      ],
      "metadata": {
        "id": "hejrZnp8gJTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1=\"text-davinci-001\"\n",
        "p2=\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"She loved the new Batman movie! But I agreed with that critic we just heard.\\\"\\nSentiment:\"\n",
        "p3=0\n",
        "p4=60\n",
        "p5=1\n",
        "p6=0.5\n",
        "p7=0\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,logprobs=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di2Yi7h6gUPQ",
        "outputId": "42183279-a2e1-499a-bb21-4d6f46baabca"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Is the following tweet postive, negative or neutral:She loved the new Batman movie! But I agreed with that critic we just heard.\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9KbEjVTSYvo",
        "outputId": "41110494-d4fb-474d-b857-a7cffac09297"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The tweet is neutral because it expresses both positive and negative opinions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Is the following tweet postive, negative or neutral:She loved the new Batman movie! But I agreed with that critic we just heard.\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnEW3yMPSoCw",
        "outputId": "7b1c5133-92cd-48a9-8ddf-88a4ea971563"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The following tweet is mixed in tone, as it expresses some positive sentiment (\"She loved the new Batman movie!\") and some negative sentiment (\"But I agreed with that critic we just heard.\"). So, it is neither purely positive, negative, nor neutral.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A translation that failed"
      ],
      "metadata": {
        "id": "mAUYIgqAgv66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1=\"davinci\"\n",
        "p2=\"Original: Elle a un cheveu sur la langue.\\n American English with no contractions:\"\n",
        "p3=0 \n",
        "p4=60\n",
        "p5=1.0\n",
        "p6=0.0\n",
        "p7=0.0\n",
        "p8=[\"\\n\"]\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,stop=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdeR2pgbg1Ml",
        "outputId": "7ab68123-5fa9-435e-ee04-4fbaa097cdc7"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " She has a hair on her tongue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Translate from French to English: Elle a un cheveu sur la langue\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9IZj4gORen3",
        "outputId": "bdfcd4e2-82ef-4290-efc2-8e1a5cd895da"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The literal translation of \"Elle a un cheveu sur la langue\" is \"She has a hair on her tongue\". However, this is a French expression which means that someone has a speech impediment, specifically a slight stutter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Translate from French to English: Elle a un cheveu sur la langue\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KSbNOi6Rs8N",
        "outputId": "2ad5af30-25b3-4dd6-8bb1-c73453eaa988"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: She has a lisp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Google Search Prompt Optimizing"
      ],
      "metadata": {
        "id": "GU5u6yjDHBN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1=\"davinci\"\n",
        "p2=\"Explain the solar system for children in a few lines:\"\n",
        "p3=0.7\n",
        "p4=64\n",
        "p5=1\n",
        "p6=0\n",
        "p7=0\n",
        "\n",
        "response = openai.Completion.create(engine=p1,prompt=p2,temperature=p3,max_tokens=p4,top_p=p5,frequency_penalty=p6,presence_penalty=p7,stop=p8)\n",
        "r = (response[\"choices\"][0])\n",
        "print(r[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fZeBn4qHD0-",
        "outputId": "94b3ef39-c830-41fa-d595-97191d04db18"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the sun, the planets and the satellites that revolve around them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Explain the solar system for children in a few lines:\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paSL-fo2R_Q5",
        "outputId": "c59983c6-5a93-4bd0-ed89-b27cc2da1abc"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The solar system consists of the sun at the center, and eight planets including Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune orbiting around the sun. These planets are different sizes and distances from the sun. There are also dwarf planets, asteroids, comets, and other objects orbiting the sun. Each planet has unique features and characteristics that make them special.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uinput=\"Explain the solar system for children in a few lines:\"\n",
        "iprompt=prepare_message(uinput) #preparing the messages for ChatGPT\n",
        "response=openai.ChatCompletion.create(model=\"gpt-4\",messages=iprompt) #ChatGPT dialog\n",
        "text=response[\"choices\"][0][\"message\"][\"content\"] #response in JSON\n",
        "print(\"ChatGPT response:\",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEaB36aKSGst",
        "outputId": "7fb53688-27a3-4036-bf13-1b22bb410d4a"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT response: The solar system is like a big family in space. At the center, we have the Sun, which is a giant ball of hot, glowing gas that gives us light and warmth. Then, there are 8 planets that orbit, or move around, the Sun. These planets are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Some of them have moons, and there are even special rocks called asteroids and comets that fly around too. We all live together in this huge cosmic neighborhood!\n"
          ]
        }
      ]
    }
  ]
}