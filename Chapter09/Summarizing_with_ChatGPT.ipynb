{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_QjF04i9neT"
      },
      "source": [
        "#Summarizing_with_ChatGPT\n",
        "Copyright 2023 Denis Rothman, MIT License\n",
        "\n",
        "**March 2023 message by Denis Rothman:**\n",
        "This notebook replaces[Training_OpenAI_GPT_2_CH09.ipynb](https://github.com/Denis2054/Transformers-for-NLP-2nd-Edition/blob/main/Chapter09/Training_OpenAI_GPT_2_CH09.ipynb). Google Colab does not support Tensorflow 1.x anymore which makes the Training_OpenAI_GPT_2_CH09.ipybn notebook unstable.\n",
        "\n",
        "The goal of *Transformers for NLP, 2nd Edition, Chapter 9, Matching Tokenizers and Datasets*, is to show how tokenizing works and the limitations of transformer models when embedding tokens.\n",
        "\n",
        "This notebook shows how to use GPT-3.5(ChatGPT) with the OpenAI API to perform the summarization task of chapter 9, experimenting with rare words and showing the limits of SOA transformers no matter how evolved they are:\n",
        "\n",
        "1. Installing openai and your API key<br>\n",
        "2. Summarization<br>\n",
        "3. Tokenizing<br>\n",
        "4. Exploring the limits<br>\n",
        "5. Conclusion<br>\n",
        "\n",
        "To get the best out of this notebook:\n",
        "\n",
        "*  make sure you have read Chapter 7\n",
        "\n",
        "*  once you have understood the theory, go to section 4 of this notebook,  *4. Exploring the limits*, of this notebook and try to find more limitations and think of how you can filter them and find solutions.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6tKx3NO4dSL"
      },
      "source": [
        "# December 6,2023 OpenAI API update\n",
        "\n",
        "[This notebook has been updated. See README \"Getting Started with OpenAI API\" section before running this notebook](https://github.com/Denis2054/Transformers-for-NLP-2nd-Edition/blob/main/README.md#getting-started-with-openai-api)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUn5YJeQvy-F",
        "outputId": "6ba31734-d5d4-4b4b-a966-3511d5479b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o668nADc4hNp",
        "outputId": "1a4a6fb3-6b89-4e09-f699-72a6f662d7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
            "Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting cohere\n",
            "  Downloading cohere-4.37-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
            "Downloading cohere-4.37-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastavro, backoff, cohere\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.37 fastavro-1.9.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# December 4,2023 update : Tiktoken required to install OpenAI on Google Colab\n",
        "# Tiktoken is a fast BPE tokenizer\n",
        "!pip install tiktoken\n",
        "\n",
        "# December 4,2023 update : Cohere required to install OpenAI to implement language AI.\n",
        "# Cohere platform: https://dashboard.cohere.com/\n",
        "!pip install --upgrade cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-crABM8l3Xi"
      },
      "source": [
        "#1.Installing openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygFUriSCvTNb"
      },
      "source": [
        "## installing and importing openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G79pIy_Mg5Y",
        "outputId": "dc5fa4d0-f535-4f51-e776-0cf15fd6f86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Importing openai\n",
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7YHxHaLmAEi"
      },
      "source": [
        "##API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Eb6gFplQqU5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d0cd21-25d1-499e-8612-56c13b74e314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#2.API Key\n",
        "#Store you key in a file and read it(you can type it directly in the notebook but it will be visible for somebody next to you)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()\n",
        "\n",
        "#The OpenAI Key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U03EQHLtmZLl"
      },
      "source": [
        "#2. gpt-3.5 turbo(ChatGPT) dialog function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1moBmYTVp-ih"
      },
      "source": [
        "preparing the NLP message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wl_ih8tPqebL"
      },
      "outputs": [],
      "source": [
        " def dialog(uinput):\n",
        "   #preparing the prompt for OpenAI\n",
        "   role=\"user\"\n",
        "\n",
        "   #prompt=\"Where is Tahiti located?\" #maintenance or if you do not want to use a microphone\n",
        "   line = {\"role\": role, \"content\": uinput}\n",
        "\n",
        "   #creating the mesage\n",
        "   assert1={\"role\": \"system\", \"content\": \"You are a Natural Language Processing Assistant.\"}\n",
        "   assert2={\"role\": \"assistant\", \"content\": \"You are helping viewers analyze social medial better.\"}\n",
        "   assert3=line\n",
        "   iprompt = []\n",
        "   iprompt.append(assert1)\n",
        "   iprompt.append(assert2)\n",
        "   iprompt.append(assert3)\n",
        "\n",
        "   #sending the message to ChatGPT\n",
        "   import os\n",
        "   from openai import OpenAI\n",
        "\n",
        "   client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "   response=client.chat.completions.create(model=\"gpt-3.5-turbo\",messages=iprompt) #ChatGPT dialog\n",
        "\n",
        "   return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-qY6V3mqMEb"
      },
      "source": [
        "# 3.Summarizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKnTT3-j3TjG"
      },
      "source": [
        "The next to summarize:\n",
        "\n",
        "\"During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21].\"\n",
        "\n",
        "\n",
        "The summary by ChatGPT seems acceptable but implementing controlls by an SME(Subject Matter Expert) is good practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vM6fWKbit8qV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597b66e1-947c-4536-ea8b-1fb0f668562e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Viewer request Summarize the following paragraph: During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21].\n",
            "ChatGPT response: Cells have the ability to sense and respond to external factors, leading to migration in a specific direction. This directed migration can be influenced by biochemical cues such as soluble factors or growth factors, as well as biophysical cues like the alignment and stiffness of the extracellular matrix. Examples of mono-directional stimuli include chemotaxis, haptotaxis, durotaxis, electrotaxis, and phototaxis. The alignment of collagen fibers in the extracellular matrix is particularly important in stimulating contact guidance.\n"
          ]
        }
      ],
      "source": [
        "uinput=\"Summarize the following paragraph: During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21].\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPgasm5AvZi2"
      },
      "source": [
        "# 4.Exploring the limits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bL9Aa3S7F4E"
      },
      "source": [
        "In chapter, GPT-2 struggles with \"amoeboid\". GPT-3.5 turbo(ChatGPT) finds the correct definition even in a difficult sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V35q2q7Z5e6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4473c90-755d-4c4c-db85-69ef00e9b5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Viewer request Explain this sentence: I don't use a false foot to move forward so I am not an amoeboid today.\n",
            "ChatGPT response: This sentence is an example of figurative language and can be interpreted metaphorically. \n",
            "\n",
            "The phrase \"I don't use a false foot to move forward\" suggests that the speaker does not rely on deceptive tactics or dishonesty to make progress or achieve their goals. It implies that they believe in being genuine and authentic in their approach to life.\n",
            "\n",
            "The second part of the sentence, \"so I am not an amoeboid today,\" adds further metaphorical meaning. Amoeboid is derived from the word amoeba, which is a single-celled organism that can change its shape or direction of movement. In this context, being \"amoeboid\" metaphorically signifies being aimless, indecisive, or lacking a clear purpose.\n",
            "\n",
            "By stating \"I am not an amoeboid today,\" the speaker is asserting that they are not feeling directionless or unsure about their path or actions at the present moment. They are emphasizing their commitment to moving forward honestly and purposefully.\n"
          ]
        }
      ],
      "source": [
        "#amoeboid\n",
        "uinput=\"Explain this sentence: I don't use a false foot to move forward so I am not an amoeboid today.\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI5dlRMa8PNJ"
      },
      "source": [
        "ChatGPT struggles with  [\"icing\" in hockey](https://www.merriam-webster.com/dictionary/icing)\n",
        "\n",
        "\"pucks\" is translated as nonesense in Frence as of March 15th, 2023. This might improve in the future.\n",
        "\n",
        "Viewer request English to French: Icing pucks is fun!\n",
        "ChatGPT response: Glaçage des rondelles est amusant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_J0HzHa7V83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3428c570-0dbd-4d41-e284-a538faa68a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Viewer request English to French: Icing pucks is fun!\n",
            "ChatGPT response: Glaçage des rondelles est amusant !\n"
          ]
        }
      ],
      "source": [
        "#The verb to ice pucks\n",
        "uinput=\"English to French: Icing pucks is fun!\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0fLQ9Gf9bA0"
      },
      "source": [
        "The back translation produces nonesense:\n",
        "\n",
        "Viewer request French to English: \"Glaçage des rondelles est amusant!!\"\n",
        "ChatGPT response: \"Icing the slices is fun!!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_HzIAAs19UOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131b4527-f757-4d79-cea4-d0f5a5964edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Viewer request French to English: Glaçage des rondelles est amusant!!\n",
            "ChatGPT response: Icing the rounds is fun!!\n"
          ]
        }
      ],
      "source": [
        "#The verb to ice pucks\n",
        "uinput=\"French to English: Glaçage des rondelles est amusant!!\"\n",
        "response=dialog(uinput) #preparing the messages for ChatGPT\n",
        "print(\"Viewer request\",uinput)\n",
        "print(\"ChatGPT response:\",response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czjyu19-9i7q"
      },
      "source": [
        "# 5.Conclusion\n",
        "\n",
        "GPT-2 has reached it limits.\n",
        "\n",
        "GPT-3.5 turbo(ChatGPT) represents a huge step forward.\n",
        "\n",
        "We simply have to accept the limitations and provide altternative solutions when we reach them.\n",
        "\n",
        "There is still much work to do!\n",
        "\n",
        "Next Steps: Explore SOA examples in the [BONUS](https://github.com/Denis2054/Transformers-for-NLP-2nd-Edition/blob/main/Bonus/Readme.md) section! See what they can do and take them to their limits!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}