{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis2054/Transformers-for-NLP-2nd-Edition/blob/main/Chapter07/Getting_Started_GPT_4_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPM-W5IVxfJS"
      },
      "source": [
        "# Getting Started with GPT-4 API\n",
        "\n",
        "copyright 2024 Denis Rothman\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image     #This is used for rendering images in the notebook"
      ],
      "metadata": {
        "id": "1yf-ju9P62Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7HO_zOAaA-Y"
      },
      "source": [
        "## Step 1: Installing & importing OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "fdfE-07V_jzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "_8Uzj4_w_lea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS_Qk62FxclT"
      },
      "source": [
        "try:\n",
        "  import openai\n",
        "except:\n",
        "  !pip install openai\n",
        "  import openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnKbbxVMaYqy"
      },
      "source": [
        "## Step 2: Entering the API KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "21LhKHnrxA5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "k8cmujpyxKjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentification\n",
        "\n",
        "Setting the environment variable OPENAI_API_KEY to the value of API_KEY"
      ],
      "metadata": {
        "id": "PTD5NZ4Ox-G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "NAzxa-GRx8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d0bggZX_dw"
      },
      "source": [
        "## Step 3: Running an NLP tasks with the default parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKwqIwACcB2B"
      },
      "source": [
        "## Step 4: Example 1: Grammar correction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkZrsEzzNwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6dde8a3-affe-471f-9e01-bb2c58409242"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"She no went to the market.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "She didn't go to the market.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh1AuRliZVfS"
      },
      "source": [
        "## Example 2: Translation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlRVPjEMBBI2",
        "outputId": "77bf4b9b-bc13-42b9-cf3f-6634d955e9fd"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with sentences, and your task translate from English into French.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"She did not go to the market.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elle n'est pas all√©e au march√©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMUpe35ZA-t"
      },
      "source": [
        "## Example 3: Time Complexity\n",
        "\n",
        "https://platform.openai.com/examples/default-time-complexity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with Python code, and your task is to calculate its time complexity.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"def foo(n, k):\\n        accum = 0\\n        for i in range(n):\\n            for l in range(k):\\n                accum += i\\n        return accum\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "2jYE2kxxQocx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd8446e-27e0-479d-e1fa-01cced458a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time complexity of the provided Python code is O(n*k). \n",
            "\n",
            "This is because there are two nested loops in the code. The outer loop runs 'n' times and the inner loop runs 'k' times. Therefore, the total number of operations is the product of 'n' and 'k'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWGCjioUawKp"
      },
      "source": [
        "## Example 4: Text to emoji\n",
        "\n",
        "https://platform.openai.com/examples/default-emoji-translation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with text, and your task is to translate it into emojis. Do not use any regular text. Do your best with emojis only.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Artificial intelligence is a technology with great promise.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.8,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "-S7qedUIR7Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de311cc6-4c9d-4e7a-f952-e4da1caa96cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñüí°üî¨üìàüåêüí´\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrS3kT-ebaT9"
      },
      "source": [
        "## Example 5: Spreadsheet creator\n",
        "\n",
        "https://platform.openai.com/examples/default-spreadsheet-gen\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Create a two-column CSV of top science fiction movies along with the year of release.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.5,\n",
        "  max_tokens=300,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "J3yGaCEdR49a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10477644-054d-4873-e16b-a6955dcda326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie Title,Year of Release\n",
            "\"2001: A Space Odyssey\",1968\n",
            "\"Blade Runner\",1982\n",
            "\"Star Wars: Episode IV - A New Hope\",1977\n",
            "\"The Matrix\",1999\n",
            "\"Inception\",2010\n",
            "\"Star Trek\",2009\n",
            "\"Interstellar\",2014\n",
            "\"Mad Max: Fury Road\",2015\n",
            "\"Avatar\",2009\n",
            "\"The Day the Earth Stood Still\",1951\n",
            "\"Close Encounters of the Third Kind\",1977\n",
            "\"E.T. the Extra-Terrestrial\",1982\n",
            "\"The War of the Worlds\",1953\n",
            "\"Jurassic Park\",1993\n",
            "\"The Fifth Element\",1997\n",
            "\"Minority Report\",2002\n",
            "\"The Terminator\",1984\n",
            "\"Back to the Future\",1985\n",
            "\"Star Wars: Episode V - The Empire Strikes Back\",1980\n",
            "\"Alien\",1979\n",
            "\"Star Wars: Episode VI - Return of the Jedi\",1983\n",
            "\"Guardians of the Galaxy\",2014\n",
            "\"Star Trek Into Darkness\",2013\n",
            "\"Star Wars: The Force Awakens\",2015\n",
            "\"Gravity\",2013\n",
            "\"The Martian\",2015\n",
            "\"District 9\",2009\n",
            "\"Arrival\",2016\n",
            "\"Blade Runner 2049\",2017\n",
            "\"A Quiet Place\",2018\n",
            "\"Star Wars: Episode VIII - The Last Jedi\",2017\n",
            "\"Avengers: Endgame\",2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNY5uUu6ead0"
      },
      "source": [
        "## Example 6: Advanced Tweet classifier\n",
        "\n",
        "https://beta.openai.com/examples/default-tweet-classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDeD3FkbearQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77872ddb-b132-45b9-c18b-2b67e819a26d"
      },
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"I loved the new Batman movie!\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Qiw1mjcmd6"
      },
      "source": [
        "## Example 7: Natural Language to SQL\n",
        "\n",
        "https://platform.openai.com/examples/default-sql-translate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Given the following SQL tables, your job is to write queries given a user‚Äôs request.\\n    \\n    CREATE TABLE Orders (\\n      OrderID int,\\n      CustomerID int,\\n      OrderDate datetime,\\n      OrderTime varchar(8),\\n      PRIMARY KEY (OrderID)\\n    );\\n    \\n    CREATE TABLE OrderDetails (\\n      OrderDetailID int,\\n      OrderID int,\\n      ProductID int,\\n      Quantity int,\\n      PRIMARY KEY (OrderDetailID)\\n    );\\n    \\n    CREATE TABLE Products (\\n      ProductID int,\\n      ProductName varchar(50),\\n      Category varchar(50),\\n      UnitPrice decimal(10, 2),\\n      Stock int,\\n      PRIMARY KEY (ProductID)\\n    );\\n    \\n    CREATE TABLE Customers (\\n      CustomerID int,\\n      FirstName varchar(50),\\n      LastName varchar(50),\\n      Email varchar(100),\\n      Phone varchar(20),\\n      PRIMARY KEY (CustomerID)\\n    );\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Write a SQL query which computes the average total order value for all orders on 2023-04-01.\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "qALmluVsWEnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dc87e5-e91c-475e-accd-649fa8f6f7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To compute the average total order value for all orders on 2023-04-01, we first need to calculate the total order value for each order. This can be done by joining the Orders and OrderDetails tables on OrderID, and then multiplying the Quantity of each product in an order by the UnitPrice of that product from the Products table. We then group by OrderID to get the total value for each order. Finally, we calculate the average of these total order values.\n",
            "\n",
            "Here is the SQL query:\n",
            "\n",
            "    SELECT AVG(TotalOrderValue) as AverageOrderValue\n",
            "    FROM (\n",
            "        SELECT o.OrderID, SUM(od.Quantity * p.UnitPrice) as TotalOrderValue\n",
            "        FROM Orders o\n",
            "        JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
            "        JOIN Products p ON od.ProductID = p.ProductID\n",
            "        WHERE o.OrderDate = '2023-04-01'\n",
            "        GROUP BY o.OrderID\n",
            "    ) as OrderValues;\n"
          ]
        }
      ]
    }
  ]
}